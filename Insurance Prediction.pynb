{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "****# Insurance cost prediction using linear regression\n",
    "\n",
    "In this project we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n",
    "\n",
    "\n",
    "We will create a model with the following steps:\n",
    "1. Download and explore the dataset\n",
    "2. Prepare the dataset for training\n",
    "3. Create a linear regression model\n",
    "4. Train the model to fit the data\n",
    "5. Make predictions using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download and explore the data\n",
    "\n",
    "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv to ./insurance.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0879e1c586442386ca9328c08264ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = 'Harshada' # at least 5 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows\n",
    "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['region'], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>38</td>\n",
       "      <td>male</td>\n",
       "      <td>37.2383</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>47822.138274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>47</td>\n",
       "      <td>female</td>\n",
       "      <td>25.8020</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>11076.058740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>32.1070</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>26314.569076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>24.6962</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>8067.995916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>62</td>\n",
       "      <td>female</td>\n",
       "      <td>24.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>15334.279080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex      bmi  children smoker       charges\n",
       "1111   38    male  37.2383         3    yes  47822.138274\n",
       "275    47  female  25.8020         2     no  11076.058740\n",
       "430    19    male  32.1070         0     no  26314.569076\n",
       "154    40  female  24.6962         1     no   8067.995916\n",
       "920    62  female  24.2500         0     no  15334.279080"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us answer some basic questions about the dataset. \n",
    "\n",
    "**Total number of observations in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "num_rows = dataframe.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "num_cols = dataframe.shape[1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'charges'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['age', 'sex', 'bmi', 'children', 'smoker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'children', 'smoker']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical features**\n",
    "\n",
    "Hint: `sex` is one of them. List the columns that are not numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=[x for x in input_cols if(dataframe[x].dtype==object)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'smoker']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output/ Target variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charges']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_cols = ['charges']\n",
    "output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the minimum, maximum and average charges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_charges = dataframe.charges.mean()\n",
    "max_charge = dataframe.charges.max()\n",
    "min_charge = dataframe.charges.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15105.227761890697 1278.9362460000002 72698.2879314\n"
     ]
    }
   ],
   "source": [
    "print(average_charges,min_charge,max_charge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dataframe[\"charges\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the dataset for training\n",
    "\n",
    "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[38.     ,  1.     , 37.2383 ,  3.     ,  1.     ],\n",
       "        [47.     ,  0.     , 25.802  ,  2.     ,  0.     ],\n",
       "        [19.     ,  1.     , 32.107  ,  0.     ,  0.     ],\n",
       "        ...,\n",
       "        [23.     ,  1.     , 23.12965,  0.     ,  0.     ],\n",
       "        [30.     ,  0.     , 21.28665,  1.     ,  0.     ],\n",
       "        [56.     ,  0.     , 24.8805 ,  0.     ,  0.     ]]),\n",
       " array([[47822.138274 ],\n",
       "        [11076.05874  ],\n",
       "        [26314.5690762],\n",
       "        ...,\n",
       "        [ 2730.495567 ],\n",
       "        [ 5378.752047 ],\n",
       "        [13057.58451  ]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs_array).type(torch.float32)\n",
    "targets = torch.from_numpy(targets_array).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percent = 0.17 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "train_ds, val_ds = random_split(dataset,[train_size,val_size])\n",
    "# Use the random_split function to split dataset into 2 parts of the desired length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create data loaders for training & validation.\n",
    "\n",
    "**Picking a batch size for the data loader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a batch of data to verify everything is working fine so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[29.0000,  1.0000, 28.1057,  1.0000,  0.0000],\n",
      "        [64.0000,  1.0000, 23.9590,  1.0000,  0.0000],\n",
      "        [53.0000,  1.0000, 29.5802,  0.0000,  0.0000],\n",
      "        [41.0000,  0.0000, 27.2085,  1.0000,  0.0000],\n",
      "        [57.0000,  1.0000, 27.2570,  0.0000,  0.0000],\n",
      "        [20.0000,  0.0000, 21.7474,  0.0000,  1.0000],\n",
      "        [48.0000,  0.0000, 32.1167,  0.0000,  1.0000],\n",
      "        [44.0000,  0.0000, 25.6177,  0.0000,  0.0000],\n",
      "        [59.0000,  1.0000, 23.9590,  0.0000,  0.0000],\n",
      "        [58.0000,  0.0000, 35.3856,  0.0000,  0.0000],\n",
      "        [57.0000,  1.0000, 39.7166,  0.0000,  0.0000],\n",
      "        [63.0000,  0.0000, 22.3925,  0.0000,  0.0000],\n",
      "        [34.0000,  1.0000, 33.6348,  0.0000,  0.0000],\n",
      "        [41.0000,  1.0000, 23.2218,  1.0000,  0.0000],\n",
      "        [20.0000,  1.0000, 28.8430,  0.0000,  0.0000],\n",
      "        [41.0000,  0.0000, 34.9976,  1.0000,  0.0000],\n",
      "        [50.0000,  0.0000, 27.3152,  3.0000,  0.0000],\n",
      "        [32.0000,  1.0000, 30.5550,  1.0000,  0.0000],\n",
      "        [62.0000,  1.0000, 37.6651,  0.0000,  0.0000],\n",
      "        [19.0000,  1.0000, 27.5480,  1.0000,  0.0000],\n",
      "        [38.0000,  1.0000, 16.3106,  2.0000,  0.0000],\n",
      "        [25.0000,  1.0000, 44.1738,  2.0000,  1.0000],\n",
      "        [49.0000,  1.0000, 25.0648,  1.0000,  0.0000],\n",
      "        [46.0000,  0.0000, 34.4641,  0.0000,  1.0000],\n",
      "        [46.0000,  0.0000, 26.9078,  0.0000,  0.0000],\n",
      "        [30.0000,  1.0000, 37.6651,  1.0000,  0.0000],\n",
      "        [20.0000,  1.0000, 29.2115,  5.0000,  0.0000],\n",
      "        [40.0000,  1.0000, 39.9931,  1.0000,  0.0000],\n",
      "        [45.0000,  0.0000, 38.7952,  3.0000,  0.0000],\n",
      "        [64.0000,  0.0000, 38.5090,  0.0000,  0.0000],\n",
      "        [43.0000,  0.0000, 24.5119,  1.0000,  1.0000],\n",
      "        [32.0000,  0.0000, 28.7023,  1.0000,  0.0000],\n",
      "        [52.0000,  0.0000, 23.4061,  1.0000,  1.0000],\n",
      "        [46.0000,  1.0000, 24.0511,  3.0000,  0.0000],\n",
      "        [40.0000,  1.0000, 34.2410,  3.0000,  0.0000],\n",
      "        [44.0000,  0.0000, 35.3856,  0.0000,  0.0000],\n",
      "        [53.0000,  0.0000, 32.2525,  0.0000,  0.0000],\n",
      "        [34.0000,  0.0000, 36.8600,  3.0000,  0.0000],\n",
      "        [43.0000,  0.0000, 34.5708,  1.0000,  0.0000],\n",
      "        [19.0000,  1.0000, 35.8464,  0.0000,  1.0000],\n",
      "        [22.0000,  1.0000, 28.0136,  0.0000,  0.0000],\n",
      "        [51.0000,  0.0000, 35.9385,  3.0000,  1.0000],\n",
      "        [27.0000,  1.0000, 22.4070,  0.0000,  0.0000],\n",
      "        [24.0000,  0.0000, 29.1970,  3.0000,  0.0000],\n",
      "        [58.0000,  0.0000, 30.8703,  2.0000,  0.0000],\n",
      "        [57.0000,  0.0000, 23.2606,  1.0000,  0.0000],\n",
      "        [45.0000,  1.0000, 22.8532,  2.0000,  0.0000],\n",
      "        [19.0000,  0.0000, 27.4607,  0.0000,  1.0000],\n",
      "        [36.0000,  1.0000, 32.3980,  2.0000,  1.0000],\n",
      "        [51.0000,  1.0000, 24.0511,  2.0000,  1.0000],\n",
      "        [20.0000,  1.0000, 26.4810,  0.0000,  1.0000],\n",
      "        [61.0000,  0.0000, 24.3276,  0.0000,  0.0000],\n",
      "        [28.0000,  1.0000, 34.3719,  0.0000,  0.0000],\n",
      "        [35.0000,  1.0000, 26.2870,  1.0000,  0.0000],\n",
      "        [20.0000,  0.0000, 28.1057,  0.0000,  0.0000],\n",
      "        [55.0000,  0.0000, 24.6040,  3.0000,  0.0000],\n",
      "        [31.0000,  0.0000, 35.5311,  2.0000,  0.0000],\n",
      "        [36.0000,  1.0000, 27.1842,  1.0000,  1.0000],\n",
      "        [18.0000,  0.0000, 30.4095,  0.0000,  0.0000],\n",
      "        [20.0000,  0.0000, 30.8363,  2.0000,  0.0000],\n",
      "        [19.0000,  1.0000, 26.8690,  0.0000,  1.0000],\n",
      "        [60.0000,  1.0000, 27.7372,  0.0000,  0.0000],\n",
      "        [37.0000,  1.0000, 28.9060,  0.0000,  0.0000],\n",
      "        [21.0000,  0.0000, 25.0260,  0.0000,  0.0000]])\n",
      "targets: tensor([[ 4606.2363],\n",
      "        [34389.9453],\n",
      "        [11482.1426],\n",
      "        [ 7718.0195],\n",
      "        [12500.6084],\n",
      "        [16771.3887],\n",
      "        [46710.5469],\n",
      "        [ 8458.2051],\n",
      "        [14049.2871],\n",
      "        [13948.8564],\n",
      "        [13185.5830],\n",
      "        [16475.0918],\n",
      "        [ 5151.4619],\n",
      "        [ 7818.6665],\n",
      "        [ 2017.2661],\n",
      "        [ 7730.7437],\n",
      "        [12201.0127],\n",
      "        [ 4647.2065],\n",
      "        [14798.7344],\n",
      "        [ 2100.4717],\n",
      "        [ 7570.2212],\n",
      "        [48007.9492],\n",
      "        [10582.0283],\n",
      "        [48007.2969],\n",
      "        [ 9150.4004],\n",
      "        [21618.0156],\n",
      "        [ 5603.1685],\n",
      "        [ 7535.5249],\n",
      "        [11063.3213],\n",
      "        [16323.6953],\n",
      "        [24819.3301],\n",
      "        [ 5201.6401],\n",
      "        [27231.9355],\n",
      "        [10830.6533],\n",
      "        [ 8204.4287],\n",
      "        [14588.8193],\n",
      "        [12043.9688],\n",
      "        [ 7063.9507],\n",
      "        [ 8374.1279],\n",
      "        [41290.1211],\n",
      "        [ 2565.9521],\n",
      "        [52730.8281],\n",
      "        [ 2831.4590],\n",
      "        [ 4827.8169],\n",
      "        [15512.4004],\n",
      "        [25299.3789],\n",
      "        [ 9808.3584],\n",
      "        [19914.6426],\n",
      "        [43793.6406],\n",
      "        [27322.8164],\n",
      "        [18505.4453],\n",
      "        [27944.9238],\n",
      "        [ 3726.4851],\n",
      "        [ 5410.8320],\n",
      "        [ 2573.5217],\n",
      "        [14873.9590],\n",
      "        [ 5642.7251],\n",
      "        [23681.9355],\n",
      "        [ 1849.2949],\n",
      "        [ 3484.2825],\n",
      "        [18579.5449],\n",
      "        [34496.3945],\n",
      "        [23279.4902],\n",
      "        [ 2289.0574]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb)\n",
    "    print(\"targets:\", yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Linear Regression Model\n",
    "\n",
    "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size,output_size)                # fill this (hint: use input_size & output_size defined above)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.linear(xb)                         # fill this\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.smooth_l1_loss(out,targets)                      # fill this\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.smooth_l1_loss(out,targets)                           # fill this    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the weights and biases of the model using `model.parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4083,  0.1870,  0.3993,  0.3796,  0.0770]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3522], requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final commit before we train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the model to fit the data\n",
    "\n",
    "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the `evaluate` function to calculate the loss on the validation set before training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 14489.8955078125}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model,val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model 4-5 times with different learning rates & for different number of epochs.**\n",
    "\n",
    "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 14408.1660\n",
      "Epoch [40], val_loss: 14326.3809\n",
      "Epoch [60], val_loss: 14244.5967\n",
      "Epoch [80], val_loss: 14162.8232\n",
      "Epoch [100], val_loss: 14081.0234\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 1e-4\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7599.8540\n",
      "Epoch [40], val_loss: 7297.6094\n",
      "Epoch [60], val_loss: 7248.8398\n",
      "Epoch [80], val_loss: 7245.0273\n",
      "Epoch [100], val_loss: 7245.9502\n"
     ]
    }
   ],
   "source": [
    "model = InsuranceModel()\n",
    "epochs = 100\n",
    "lr = 1e-1\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 13669.3174\n",
      "Epoch [40], val_loss: 12851.9697\n",
      "Epoch [60], val_loss: 12059.9805\n",
      "Epoch [80], val_loss: 11328.1543\n",
      "Epoch [100], val_loss: 10696.2578\n",
      "Epoch [120], val_loss: 10180.6689\n"
     ]
    }
   ],
   "source": [
    "model = InsuranceModel()\n",
    "epochs = 120\n",
    "lr = 1e-3\n",
    "history4 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7601.8203\n",
      "Epoch [40], val_loss: 7297.0811\n",
      "Epoch [60], val_loss: 7250.5122\n",
      "Epoch [80], val_loss: 7247.3223\n",
      "Epoch [100], val_loss: 7242.0493\n",
      "Epoch [120], val_loss: 7240.6294\n",
      "Epoch [140], val_loss: 7240.3135\n",
      "Epoch [160], val_loss: 7230.7500\n",
      "Epoch [180], val_loss: 7226.8271\n",
      "Epoch [200], val_loss: 7220.7935\n"
     ]
    }
   ],
   "source": [
    "model = InsuranceModel()\n",
    "epochs = 200\n",
    "lr = 1e-1\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final validation loss of your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = history2[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Making predictions using the trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)                # fill this\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([55.0000,  0.0000, 35.9870,  0.0000,  0.0000])\n",
      "Target: tensor([12213.5537])\n",
      "Prediction: tensor([12520.0420])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([19.0000,  1.0000, 24.4198,  0.0000,  0.0000])\n",
      "Target: tensor([1860.5214])\n",
      "Prediction: tensor([3110.0464])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([20.0000,  0.0000, 30.9624,  0.0000,  0.0000])\n",
      "Target: tensor([2578.1885])\n",
      "Prediction: tensor([2780.1499])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
